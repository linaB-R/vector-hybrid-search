# B√∫squeda H√≠brida Vectorial

Un **sistema inteligente de b√∫squeda y coincidencia h√≠brida** basado en bases de datos vectoriales.  
Este repositorio implementa el prototipo pr√°ctico de mi Tesis de M√°ster:  
*"Sistema Inteligente de B√∫squeda y Coincidencia basado en Almacenes Vectoriales" (Universidad Europea de Madrid, 2025).*

El objetivo es combinar **recuperaci√≥n l√©xica (BM25 en PostgreSQL)** con **recuperaci√≥n sem√°ntica (embeddings pgvector)** para permitir b√∫squedas eficientes en cat√°logos de productos multimodales (texto + im√°genes).  
El caso de uso objetivo son peque√±as tiendas de comercio electr√≥nico (ej., productos impresos en 3D) que necesitan b√∫squeda inteligente escalable y de bajo costo.

---

## üìå Caracter√≠sticas Principales
- **PostgreSQL + pgvector** esquema y migraciones.
- **Dise√±o de b√∫squeda h√≠brida**: l√©xica (BM25) + ANN vectorial (HNSW) + fusi√≥n de resultados.
- **Ingesta de datos**: CSV desde S3 p√∫blico ‚Üí filtrado ‚Üí Parquet ‚Üí Supabase/PostgreSQL.
  - Filtros activos por defecto en la ingesta: pa√≠ses hispanohablantes, `product_description` no nulo/ni vac√≠o, `s3_path` v√°lido y exclusi√≥n de tiendas auto-generadas (`store_name` empieza por `AS_`).
- **Relleno de embeddings (ruta principal)**:
  - Texto: Jina Embeddings v3 / JE-3 (1024D).
  - Multimodal: Jina CLIP v2 (1024D texto e imagen) para recuperaci√≥n cruzada texto‚Üîimagen.
- **Modelos adicionales (opcionales)**:
  - Texto: E5-small (384D), GTE-base (768D).
  - CLIP 512D: texto multiling√ºe alineado a imagen (512D) e imagen ViT-B/32 (512D).
- **Integraci√≥n con Supabase**: despliegue f√°cil v√≠a conexi√≥n GitHub.
- **Pipeline extensible** para futuros experimentos de b√∫squeda h√≠brida y multimodal.

### Chat y Tests
- API m√≠nima FastAPI `/chat` (texto) con b√∫squeda h√≠brida (pgvector + full-text) y fusi√≥n RRF
- Conexi√≥n Supabase v√≠a `DATABASE_URL` con `sslmode=require` (o variables discretas con SSL forzado)
- Tests de conectividad (DB y OpenAI) y test de chatbot con trazabilidad completa a `log/chat_run_<timestamp>/`
- Documentaci√≥n actualizada con pasos de ejecuci√≥n r√°pidos (uvicorn) y gu√≠a de interpretaci√≥n de logs

---

## üèóÔ∏è Fundamentos Tecnol√≥gicos y Arquitectura de Datos

### La Importancia Estrat√©gica de PostgreSQL con pgvector

La elecci√≥n de **PostgreSQL** como sistema de gesti√≥n de bases de datos relacionales para este proyecto no es casual, sino que responde a necesidades espec√≠ficas de escalabilidad, robustez y capacidades avanzadas de indexaci√≥n que son fundamentales para el √©xito de un sistema de b√∫squeda h√≠brida.

PostgreSQL se distingue por su **arquitectura extensible** que permite la integraci√≥n de extensiones especializadas como **pgvector**, transform√°ndolo de un RDBMS tradicional en una plataforma h√≠brida capaz de manejar tanto datos estructurados relacionales como vectores de alta dimensionalidad. Esta dualidad es crucial para nuestro sistema, ya que permite mantener la **consistencia ACID** de las transacciones relacionales mientras se ejecutan operaciones de b√∫squeda vectorial de manera nativa y eficiente.

La extensi√≥n **pgvector** representa un avance significativo en la democratizaci√≥n de las bases de datos vectoriales. A diferencia de soluciones especializadas como Pinecone, Weaviate o Chroma, pgvector permite implementar capacidades de b√∫squeda sem√°ntica sin la complejidad operacional de mantener sistemas distribuidos separados. Esto resulta especialmente relevante para peque√±as y medianas empresas que requieren capacidades de b√∫squeda inteligente sin los costos asociados a infraestructuras complejas.

### √çndices HNSW: Eficiencia en B√∫squeda de Vecinos M√°s Cercanos

Los **√≠ndices Hierarchical Navigable Small World (HNSW)** implementados en pgvector constituyen el n√∫cleo algor√≠tmico que hace viable la b√∫squeda vectorial a escala. HNSW representa una evoluci√≥n significativa sobre algoritmos tradicionales como LSH (Locality-Sensitive Hashing) o √°rboles KD, ofreciendo una **complejidad logar√≠tmica** en las operaciones de b√∫squeda mientras mantiene alta precisi√≥n en la recuperaci√≥n.

La arquitectura jer√°rquica de HNSW construye m√∫ltiples capas de grafos donde cada nivel superior act√∫a como un "mapa de carreteras" que gu√≠a la navegaci√≥n hacia regiones prometedoras del espacio vectorial. Esta estructura permite que las consultas de vecinos m√°s cercanos (k-NN) se ejecuten en **tiempo sublineal**, una caracter√≠stica esencial cuando se trabaja con cat√°logos de productos que pueden contener millones de elementos.

Los par√°metros configurables de HNSW (`m`, `ef_construction`, `ef_search`) permiten ajustar el balance entre **precisi√≥n, velocidad y uso de memoria**, adapt√°ndose a las caracter√≠sticas espec√≠ficas de cada dominio de aplicaci√≥n. En el contexto de comercio electr√≥nico, donde la latencia de respuesta impacta directamente en la experiencia del usuario, esta flexibilidad es fundamental.

### B√∫squeda H√≠brida: Sinergia entre Recuperaci√≥n L√©xica y Sem√°ntica

La implementaci√≥n de **b√∫squeda h√≠brida** que combina BM25 (Best Matching 25) con embeddings vectoriales representa una aproximaci√≥n hol√≠stica al problema de recuperaci√≥n de informaci√≥n. BM25, basado en el modelo probabil√≠stico de Robertson-Sparck Jones, excele en la coincidencia exacta de t√©rminos y manejo de frecuencias, mientras que los embeddings capturan relaciones sem√°nticas latentes que trascienden la coincidencia l√©xica superficial.

Esta complementariedad es especialmente valiosa en cat√°logos de productos multiling√ºes o con terminolog√≠a t√©cnica variada, donde un usuario puede buscar "smartphone resistente al agua" y encontrar productos descritos como "tel√©fono m√≥vil con certificaci√≥n IP68". La **fusi√≥n de rankings** mediante t√©cnicas como Reciprocal Rank Fusion (RRF) o aprendizaje autom√°tico permite combinar las fortalezas de ambos enfoques de manera √≥ptima.

### Amazon S3: Escalabilidad y Econom√≠a en Almacenamiento de Contenido Multimedia

La decisi√≥n de utilizar **Amazon S3** para el almacenamiento de im√°genes responde a consideraciones tanto t√©cnicas como econ√≥micas que son cr√≠ticas para la viabilidad comercial del sistema. S3 ofrece **durabilidad del 99.999999999% (11 9's)** y disponibilidad del 99.99%, garantizando que el contenido multimedia permanezca accesible incluso ante fallos de infraestructura.

La **arquitectura de almacenamiento por objetos** de S3 elimina las limitaciones de sistemas de archivos tradicionales, permitiendo escalabilidad pr√°cticamente ilimitada sin degradaci√≥n del rendimiento. Esto es fundamental cuando se considera que las im√°genes de productos de alta resoluci√≥n pueden ocupar varios megabytes cada una, y un cat√°logo empresarial puede contener cientos de miles de productos.

El modelo de **precios por uso** de S3, combinado con opciones de almacenamiento inteligente (S3 Intelligent-Tiering) y clases de almacenamiento de acceso infrecuente, permite optimizar costos autom√°ticamente bas√°ndose en patrones de acceso reales. Para startups y PYMEs, esta elasticidad econ√≥mica es crucial para mantener m√°rgenes sostenibles mientras se escala el negocio.

### Integraci√≥n Arquitect√≥nica y Consideraciones de Rendimiento

La arquitectura propuesta aprovecha las **caracter√≠sticas de localidad** inherentes tanto en PostgreSQL como en S3. Las consultas h√≠bridas se ejecutan completamente en PostgreSQL, minimizando la latencia de red, mientras que las im√°genes se sirven directamente desde S3 con **CloudFront CDN** para optimizar la entrega global.

Esta separaci√≥n de responsabilidades permite **escalado independiente** de cada componente: la base de datos puede optimizarse para throughput de consultas mientras que el almacenamiento de im√°genes se escala horizontalmente seg√∫n demanda. La **consistencia eventual** entre metadatos en PostgreSQL e im√°genes en S3 se gestiona mediante patrones de sincronizaci√≥n as√≠ncrona que mantienen la integridad del sistema sin bloqueos.

La implementaci√≥n de **conexiones pooling** y **prepared statements** en PostgreSQL, combinada con **multipart uploads** y **transfer acceleration** en S3, garantiza que el sistema pueda manejar cargas de trabajo concurrentes t√≠picas de aplicaciones de comercio electr√≥nico en producci√≥n.

---

## ‚öôÔ∏è Inicio R√°pido

### 1. Aplicar migraciones de base de datos
```powershell
python database\apply_migrations.py
````

### 2. Ingestar dataset desde S3 p√∫blico ‚Üí Parquet

```powershell
# Descarga y filtra (por defecto aplica pa√≠ses hispanohablantes y descripci√≥n no nula)
python src\ingest\ingest_s3_csv.py --max-records 100000 --output-file "data/20250123_data.parquet"

# (Opcional) Filtrar adem√°s por pa√≠ses espec√≠ficos (se intersecta con la lista hispanohablante)
python src\ingest\ingest_s3_csv.py --country-codes ES MX AR --output-file "data/latam_es.parquet"
```

### 3. Subir datos filtrados a Supabase/PostgreSQL

```powershell
python .\src\loader\upload_parquet_to_supabase.py
```

### 4. Rellenar embeddings (orden recomendado)

```powershell
# Texto ‚Üí Texto (principal: Jina JE-3)
python -m src.ingest.backfill_text_je3 --batch-size 128

# (Opcional) Texto ‚Üí Texto adicionales
python -m src.ingest.backfill_text_e5 --batch-size 512
python -m src.ingest.backfill_text_gte --batch-size 256

# Multimodal Jina CLIP v2 (texto e imagen 1024D)
python -m src.ingest.backfill_clip_v2 --mode text --batch-size 256
python -m src.ingest.backfill_clip_v2 --mode image --batch-size 128
```

> Nota: si prefieres la ruta CLIP 512D (texto multiling√ºe + ViT-B/32), usa `src/ingest/backfill_clip_512.py` con `--mode text_multi` e `--mode image`.

### 5. Ejecutar la API (uvicorn)

```powershell
uvicorn src.rag.chat_demo:app --reload --port 8000
```

### 6. Probar el chatbot y generar logs de trazabilidad

```powershell
pytest -q
```

Los resultados se guardan como JSON bajo `log/chat_run_<timestamp>/`:

- `00_meta.json`: contexto (envs, query, par√°metros)
- `01_request.json`: petici√≥n enviada
- `02_response_status.json`: c√≥digo HTTP y latencia
- `03_response_json.json`: respuesta completa (`answer` + `trace`)
- `04_sql.json`: SQL vectorial y l√©xico
- `05_candidates_vector_top.json`: top vectorial
- `06_candidates_lexical_top.json`: top l√©xico
- `07_final_fused.json`: ranking final fusionado (RRF)

---

## üì¶ Verificaciones opcionales de AWS CLI

Inspeccionar o descargar im√°genes individuales del dataset p√∫blico:

```powershell
aws s3 ls s3://glovo-products-dataset-d1c9720d/dataset/YKKVTDF_0000672_1629430873.png --no-sign-request 

aws s3 cp s3://glovo-products-dataset-d1c9720d/dataset/YKKVTDF_0000672_1629430873.png . --no-sign-request
```

---

## üóÇÔ∏è Estructura del Proyecto

```
lina/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ changelog/
‚îÇ   ‚îî‚îÄ‚îÄ CHANGELOG.md
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ data.parquet
‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îú‚îÄ‚îÄ apply_migrations.py
‚îÇ   ‚îî‚îÄ‚îÄ migrations/
‚îÇ       ‚îú‚îÄ‚îÄ 00_enable_extensions.sql
‚îÇ       ‚îú‚îÄ‚îÄ 01_create_schema.sql
‚îÇ       ‚îú‚îÄ‚îÄ 02_tables.sql
‚îÇ       ‚îú‚îÄ‚îÄ 03_indexes_hnsw.sql
‚îÇ       ‚îî‚îÄ‚îÄ [otros archivos SQL]
‚îú‚îÄ‚îÄ models_cache/
‚îÇ   ‚îú‚îÄ‚îÄ models--jinaai--jina-embeddings-v3/
‚îÇ   ‚îî‚îÄ‚îÄ models--jinaai--xlm-roberta-flash-implementation/
‚îú‚îÄ‚îÄ sandbox/
‚îÇ   ‚îú‚îÄ‚îÄ check_parquet.py
‚îÇ   ‚îî‚îÄ‚îÄ sample_foodi_dataset.py
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ text_je3.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ clip_v2.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ text_e5_small.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ text_gte_base.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ text_clip_multi.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ image_clip_vitb32.py
‚îÇ   ‚îú‚îÄ‚îÄ ingest/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backfill_text_je3.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backfill_clip_v2.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backfill_text_e5.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backfill_text_gte.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ backfill_clip_512.py
‚îÇ   ‚îî‚îÄ‚îÄ loader/
‚îÇ       ‚îî‚îÄ‚îÄ upload_parquet_to_supabase.py
‚îú‚îÄ‚îÄ .env.sample   # variables de entorno de ejemplo (a√±adir aqu√≠ los secretos necesarios)
‚îî‚îÄ‚îÄ venv/         # entorno virtual (excluido en .gitignore)
```

---

## üîÆ Pr√≥ximos Pasos

* Implementar la interfaz de ejecuci√≥n de consultas h√≠bridas.
* Evaluar rendimiento con Precision@K, Recall@K, MAP, nDCG.
* Hacer benchmark de par√°metros del √≠ndice HNSW (`m`, `ef_search`, `ef_construction`).
* Preparar documentaci√≥n y resultados de la tesis.

---

## üìñ Referencias

* [pgvector](https://github.com/pgvector/pgvector)
* Radford et al. (2021) CLIP: Contrastive Language-Image Pretraining
* Manning et al. (2008) *Introduction to Information Retrieval*
* Jurafsky & Martin (2023) *Speech and Language Processing*

