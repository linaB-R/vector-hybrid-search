# BÃºsqueda HÃ­brida Vectorial

Un **sistema inteligente de bÃºsqueda y coincidencia hÃ­brida** basado en bases de datos vectoriales.  
Este repositorio implementa el prototipo prÃ¡ctico de mi Tesis de MÃ¡ster:  
*"Sistema Inteligente de BÃºsqueda y Coincidencia basado en Almacenes Vectoriales" (Universidad Europea de Madrid, 2025).*

El objetivo es combinar **recuperaciÃ³n lÃ©xica (BM25 en PostgreSQL)** con **recuperaciÃ³n semÃ¡ntica (embeddings pgvector)** para permitir bÃºsquedas eficientes en catÃ¡logos de productos multimodales (texto + imÃ¡genes).  
El caso de uso objetivo son pequeÃ±as tiendas de comercio electrÃ³nico (ej., productos impresos en 3D) que necesitan bÃºsqueda inteligente escalable y de bajo costo.

---

## ğŸ“Œ CaracterÃ­sticas Principales
- **PostgreSQL + pgvector** esquema y migraciones.
- **DiseÃ±o de bÃºsqueda hÃ­brida**: lÃ©xica (BM25) + ANN vectorial (HNSW) + fusiÃ³n de resultados.
- **Ingesta de datos**: CSV desde S3 pÃºblico â†’ filtrado â†’ Parquet â†’ Supabase/PostgreSQL.
- **Relleno de embeddings**:
  - Embeddings de texto (Jina v3 / JE-3).
  - Embeddings de imagen (CLIP v2, multimodal).
- **IntegraciÃ³n con Supabase**: despliegue fÃ¡cil vÃ­a conexiÃ³n GitHub.
- **Pipeline extensible** para futuros experimentos de bÃºsqueda hÃ­brida y multimodal.

---

## ğŸ—ï¸ Fundamentos TecnolÃ³gicos y Arquitectura de Datos

### La Importancia EstratÃ©gica de PostgreSQL con pgvector

La elecciÃ³n de **PostgreSQL** como sistema de gestiÃ³n de bases de datos relacionales para este proyecto no es casual, sino que responde a necesidades especÃ­ficas de escalabilidad, robustez y capacidades avanzadas de indexaciÃ³n que son fundamentales para el Ã©xito de un sistema de bÃºsqueda hÃ­brida.

PostgreSQL se distingue por su **arquitectura extensible** que permite la integraciÃ³n de extensiones especializadas como **pgvector**, transformÃ¡ndolo de un RDBMS tradicional en una plataforma hÃ­brida capaz de manejar tanto datos estructurados relacionales como vectores de alta dimensionalidad. Esta dualidad es crucial para nuestro sistema, ya que permite mantener la **consistencia ACID** de las transacciones relacionales mientras se ejecutan operaciones de bÃºsqueda vectorial de manera nativa y eficiente.

La extensiÃ³n **pgvector** representa un avance significativo en la democratizaciÃ³n de las bases de datos vectoriales. A diferencia de soluciones especializadas como Pinecone, Weaviate o Chroma, pgvector permite implementar capacidades de bÃºsqueda semÃ¡ntica sin la complejidad operacional de mantener sistemas distribuidos separados. Esto resulta especialmente relevante para pequeÃ±as y medianas empresas que requieren capacidades de bÃºsqueda inteligente sin los costos asociados a infraestructuras complejas.

### Ãndices HNSW: Eficiencia en BÃºsqueda de Vecinos MÃ¡s Cercanos

Los **Ã­ndices Hierarchical Navigable Small World (HNSW)** implementados en pgvector constituyen el nÃºcleo algorÃ­tmico que hace viable la bÃºsqueda vectorial a escala. HNSW representa una evoluciÃ³n significativa sobre algoritmos tradicionales como LSH (Locality-Sensitive Hashing) o Ã¡rboles KD, ofreciendo una **complejidad logarÃ­tmica** en las operaciones de bÃºsqueda mientras mantiene alta precisiÃ³n en la recuperaciÃ³n.

La arquitectura jerÃ¡rquica de HNSW construye mÃºltiples capas de grafos donde cada nivel superior actÃºa como un "mapa de carreteras" que guÃ­a la navegaciÃ³n hacia regiones prometedoras del espacio vectorial. Esta estructura permite que las consultas de vecinos mÃ¡s cercanos (k-NN) se ejecuten en **tiempo sublineal**, una caracterÃ­stica esencial cuando se trabaja con catÃ¡logos de productos que pueden contener millones de elementos.

Los parÃ¡metros configurables de HNSW (`m`, `ef_construction`, `ef_search`) permiten ajustar el balance entre **precisiÃ³n, velocidad y uso de memoria**, adaptÃ¡ndose a las caracterÃ­sticas especÃ­ficas de cada dominio de aplicaciÃ³n. En el contexto de comercio electrÃ³nico, donde la latencia de respuesta impacta directamente en la experiencia del usuario, esta flexibilidad es fundamental.

### BÃºsqueda HÃ­brida: Sinergia entre RecuperaciÃ³n LÃ©xica y SemÃ¡ntica

La implementaciÃ³n de **bÃºsqueda hÃ­brida** que combina BM25 (Best Matching 25) con embeddings vectoriales representa una aproximaciÃ³n holÃ­stica al problema de recuperaciÃ³n de informaciÃ³n. BM25, basado en el modelo probabilÃ­stico de Robertson-Sparck Jones, excele en la coincidencia exacta de tÃ©rminos y manejo de frecuencias, mientras que los embeddings capturan relaciones semÃ¡nticas latentes que trascienden la coincidencia lÃ©xica superficial.

Esta complementariedad es especialmente valiosa en catÃ¡logos de productos multilingÃ¼es o con terminologÃ­a tÃ©cnica variada, donde un usuario puede buscar "smartphone resistente al agua" y encontrar productos descritos como "telÃ©fono mÃ³vil con certificaciÃ³n IP68". La **fusiÃ³n de rankings** mediante tÃ©cnicas como Reciprocal Rank Fusion (RRF) o aprendizaje automÃ¡tico permite combinar las fortalezas de ambos enfoques de manera Ã³ptima.

### Amazon S3: Escalabilidad y EconomÃ­a en Almacenamiento de Contenido Multimedia

La decisiÃ³n de utilizar **Amazon S3** para el almacenamiento de imÃ¡genes responde a consideraciones tanto tÃ©cnicas como econÃ³micas que son crÃ­ticas para la viabilidad comercial del sistema. S3 ofrece **durabilidad del 99.999999999% (11 9's)** y disponibilidad del 99.99%, garantizando que el contenido multimedia permanezca accesible incluso ante fallos de infraestructura.

La **arquitectura de almacenamiento por objetos** de S3 elimina las limitaciones de sistemas de archivos tradicionales, permitiendo escalabilidad prÃ¡cticamente ilimitada sin degradaciÃ³n del rendimiento. Esto es fundamental cuando se considera que las imÃ¡genes de productos de alta resoluciÃ³n pueden ocupar varios megabytes cada una, y un catÃ¡logo empresarial puede contener cientos de miles de productos.

El modelo de **precios por uso** de S3, combinado con opciones de almacenamiento inteligente (S3 Intelligent-Tiering) y clases de almacenamiento de acceso infrecuente, permite optimizar costos automÃ¡ticamente basÃ¡ndose en patrones de acceso reales. Para startups y PYMEs, esta elasticidad econÃ³mica es crucial para mantener mÃ¡rgenes sostenibles mientras se escala el negocio.

### IntegraciÃ³n ArquitectÃ³nica y Consideraciones de Rendimiento

La arquitectura propuesta aprovecha las **caracterÃ­sticas de localidad** inherentes tanto en PostgreSQL como en S3. Las consultas hÃ­bridas se ejecutan completamente en PostgreSQL, minimizando la latencia de red, mientras que las imÃ¡genes se sirven directamente desde S3 con **CloudFront CDN** para optimizar la entrega global.

Esta separaciÃ³n de responsabilidades permite **escalado independiente** de cada componente: la base de datos puede optimizarse para throughput de consultas mientras que el almacenamiento de imÃ¡genes se escala horizontalmente segÃºn demanda. La **consistencia eventual** entre metadatos en PostgreSQL e imÃ¡genes en S3 se gestiona mediante patrones de sincronizaciÃ³n asÃ­ncrona que mantienen la integridad del sistema sin bloqueos.

La implementaciÃ³n de **conexiones pooling** y **prepared statements** en PostgreSQL, combinada con **multipart uploads** y **transfer acceleration** en S3, garantiza que el sistema pueda manejar cargas de trabajo concurrentes tÃ­picas de aplicaciones de comercio electrÃ³nico en producciÃ³n.

---

## âš™ï¸ Inicio RÃ¡pido

### 1. Aplicar migraciones de base de datos
```powershell
python database\apply_migrations.py
````

### 2. Ingestar dataset desde S3 pÃºblico â†’ Parquet

```powershell
python src\ingest\ingest_s3_csv.py --max-records 100000 --output-file "data/20250123_data.parquet"
```

### 3. Subir datos filtrados a Supabase/PostgreSQL

```powershell
python .\src\loader\upload_parquet_to_supabase.py
```

### 4. Rellenar embeddings

**Embeddings de texto (JE-v3):**

```powershell
python -m src.ingest.backfill_text_je3 --batch-size 256
```

**Embeddings de imagen (CLIP-v2):**

```powershell
python -m src.ingest.backfill_clip_v2 --mode image --batch-size 64
```

**Opcional â€“ Embeddings de texto CLIP:**

```powershell
python -m src.ingest.backfill_clip_v2 --mode text --batch-size 128
```

---

## ğŸ“¦ Verificaciones opcionales de AWS CLI

Inspeccionar o descargar imÃ¡genes individuales del dataset pÃºblico:

```powershell
aws s3 ls s3://glovo-products-dataset-d1c9720d/dataset/YKKVTDF_0000672_1629430873.png --no-sign-request 

aws s3 cp s3://glovo-products-dataset-d1c9720d/dataset/YKKVTDF_0000672_1629430873.png . --no-sign-request
```

---

## ğŸ—‚ï¸ Estructura del Proyecto

```
lina/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ changelog/
â”‚   â””â”€â”€ CHANGELOG.md
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ data.parquet
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ apply_migrations.py
â”‚   â””â”€â”€ migrations/
â”‚       â”œâ”€â”€ 00_enable_extensions.sql
â”‚       â”œâ”€â”€ 01_create_schema.sql
â”‚       â”œâ”€â”€ 02_tables.sql
â”‚       â”œâ”€â”€ 03_indexes_hnsw.sql
â”‚       â””â”€â”€ [otros archivos SQL]
â”œâ”€â”€ models_cache/
â”‚   â”œâ”€â”€ models--jinaai--jina-embeddings-v3/
â”‚   â””â”€â”€ models--jinaai--xlm-roberta-flash-implementation/
â”œâ”€â”€ sandbox/
â”‚   â”œâ”€â”€ check_parquet.py
â”‚   â””â”€â”€ sample_foodi_dataset.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â”œâ”€â”€ clip_v2.py
â”‚   â”‚   â””â”€â”€ text_je3.py
â”‚   â”œâ”€â”€ ingest/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ backfill_clip_v2.py
â”‚   â”‚   â””â”€â”€ backfill_text_je3.py
â”‚   â””â”€â”€ loader/
â”‚       â””â”€â”€ upload_parquet_to_supabase.py
â”œâ”€â”€ .env.sample   # variables de entorno de ejemplo (aÃ±adir aquÃ­ los secretos necesarios)
â””â”€â”€ venv/         # entorno virtual (excluido en .gitignore)
```

---

## ğŸ”® PrÃ³ximos Pasos

* Implementar la interfaz de ejecuciÃ³n de consultas hÃ­bridas.
* Evaluar rendimiento con Precision@K, Recall@K, MAP, nDCG.
* Hacer benchmark de parÃ¡metros del Ã­ndice HNSW (`m`, `ef_search`, `ef_construction`).
* Preparar documentaciÃ³n y resultados de la tesis.

---

## ğŸ“– Referencias

* [pgvector](https://github.com/pgvector/pgvector)
* Radford et al. (2021) CLIP: Contrastive Language-Image Pretraining
* Manning et al. (2008) *Introduction to Information Retrieval*
* Jurafsky & Martin (2023) *Speech and Language Processing*

