# BÃºsqueda HÃ­brida Vectorial

Un **sistema inteligente de bÃºsqueda y coincidencia hÃ­brida** basado en bases de datos vectoriales.  
Este repositorio implementa el prototipo prÃ¡ctico de mi Tesis de MÃ¡ster:  
*"Sistema Inteligente de BÃºsqueda y Coincidencia basado en Almacenes Vectoriales" (Universidad Europea de Madrid, 2025).*

El objetivo es combinar **recuperaciÃ³n lÃ©xica (BM25 en PostgreSQL)** con **recuperaciÃ³n semÃ¡ntica (embeddings pgvector)** para permitir bÃºsquedas eficientes en catÃ¡logos de productos multimodales (texto + imÃ¡genes).  
El caso de uso objetivo son pequeÃ±as tiendas de comercio electrÃ³nico (ej., productos impresos en 3D) que necesitan bÃºsqueda inteligente escalable y de bajo costo.

---

## ğŸ“Œ CaracterÃ­sticas Principales
- **PostgreSQL + pgvector** esquema y migraciones.
- **DiseÃ±o de bÃºsqueda hÃ­brida**: lÃ©xica (BM25) + ANN vectorial (HNSW) + fusiÃ³n de resultados.
- **Ingesta de datos**: CSV desde S3 pÃºblico â†’ filtrado â†’ Parquet â†’ Supabase/PostgreSQL.
  - Filtros activos por defecto en la ingesta: paÃ­ses hispanohablantes, `product_description` no nulo/ni vacÃ­o, `s3_path` vÃ¡lido y exclusiÃ³n de tiendas auto-generadas (`store_name` empieza por `AS_`).
- **Relleno de embeddings (ruta principal)**:
  - Texto: Jina Embeddings v3 / JE-3 (1024D).
  - Multimodal: Jina CLIP v2 (1024D texto e imagen) para recuperaciÃ³n cruzada textoâ†”imagen.
- **Modelos adicionales (opcionales)**:
  - Texto: E5-small (384D), GTE-base (768D).
  - CLIP 512D: texto multilingÃ¼e alineado a imagen (512D) e imagen ViT-B/32 (512D).
- **IntegraciÃ³n con Supabase**: despliegue fÃ¡cil vÃ­a conexiÃ³n GitHub.
- **Pipeline extensible** para futuros experimentos de bÃºsqueda hÃ­brida y multimodal.

### Chat y Tests
- API mÃ­nima FastAPI `/chat` (texto) con bÃºsqueda hÃ­brida (pgvector + full-text) y fusiÃ³n RRF
- ConexiÃ³n Supabase vÃ­a `DATABASE_URL` con `sslmode=require` (o variables discretas con SSL forzado)
- Tests de conectividad (DB y OpenAI) y test de chatbot con trazabilidad completa a `log/chat_run_<timestamp>/`
- DocumentaciÃ³n actualizada con pasos de ejecuciÃ³n rÃ¡pidos (uvicorn) y guÃ­a de interpretaciÃ³n de logs

---

## ğŸ—ï¸ Fundamentos TecnolÃ³gicos y Arquitectura de Datos

### La Importancia EstratÃ©gica de PostgreSQL con pgvector

La elecciÃ³n de **PostgreSQL** como sistema de gestiÃ³n de bases de datos relacionales para este proyecto no es casual, sino que responde a necesidades especÃ­ficas de escalabilidad, robustez y capacidades avanzadas de indexaciÃ³n que son fundamentales para el Ã©xito de un sistema de bÃºsqueda hÃ­brida.

PostgreSQL se distingue por su **arquitectura extensible** que permite la integraciÃ³n de extensiones especializadas como **pgvector**, transformÃ¡ndolo de un RDBMS tradicional en una plataforma hÃ­brida capaz de manejar tanto datos estructurados relacionales como vectores de alta dimensionalidad. Esta dualidad es crucial para nuestro sistema, ya que permite mantener la **consistencia ACID** de las transacciones relacionales mientras se ejecutan operaciones de bÃºsqueda vectorial de manera nativa y eficiente.

La extensiÃ³n **pgvector** representa un avance significativo en la democratizaciÃ³n de las bases de datos vectoriales. A diferencia de soluciones especializadas como Pinecone, Weaviate o Chroma, pgvector permite implementar capacidades de bÃºsqueda semÃ¡ntica sin la complejidad operacional de mantener sistemas distribuidos separados. Esto resulta especialmente relevante para pequeÃ±as y medianas empresas que requieren capacidades de bÃºsqueda inteligente sin los costos asociados a infraestructuras complejas.

### Ãndices HNSW: Eficiencia en BÃºsqueda de Vecinos MÃ¡s Cercanos

Los **Ã­ndices Hierarchical Navigable Small World (HNSW)** implementados en pgvector constituyen el nÃºcleo algorÃ­tmico que hace viable la bÃºsqueda vectorial a escala. HNSW representa una evoluciÃ³n significativa sobre algoritmos tradicionales como LSH (Locality-Sensitive Hashing) o Ã¡rboles KD, ofreciendo una **complejidad logarÃ­tmica** en las operaciones de bÃºsqueda mientras mantiene alta precisiÃ³n en la recuperaciÃ³n.

La arquitectura jerÃ¡rquica de HNSW construye mÃºltiples capas de grafos donde cada nivel superior actÃºa como un "mapa de carreteras" que guÃ­a la navegaciÃ³n hacia regiones prometedoras del espacio vectorial. Esta estructura permite que las consultas de vecinos mÃ¡s cercanos (k-NN) se ejecuten en **tiempo sublineal**, una caracterÃ­stica esencial cuando se trabaja con catÃ¡logos de productos que pueden contener millones de elementos.

Los parÃ¡metros configurables de HNSW (`m`, `ef_construction`, `ef_search`) permiten ajustar el balance entre **precisiÃ³n, velocidad y uso de memoria**, adaptÃ¡ndose a las caracterÃ­sticas especÃ­ficas de cada dominio de aplicaciÃ³n. En el contexto de comercio electrÃ³nico, donde la latencia de respuesta impacta directamente en la experiencia del usuario, esta flexibilidad es fundamental.

### BÃºsqueda HÃ­brida: Sinergia entre RecuperaciÃ³n LÃ©xica y SemÃ¡ntica

La implementaciÃ³n de **bÃºsqueda hÃ­brida** que combina BM25 (Best Matching 25) con embeddings vectoriales representa una aproximaciÃ³n holÃ­stica al problema de recuperaciÃ³n de informaciÃ³n. BM25, basado en el modelo probabilÃ­stico de Robertson-Sparck Jones, excele en la coincidencia exacta de tÃ©rminos y manejo de frecuencias, mientras que los embeddings capturan relaciones semÃ¡nticas latentes que trascienden la coincidencia lÃ©xica superficial.

Esta complementariedad es especialmente valiosa en catÃ¡logos de productos multilingÃ¼es o con terminologÃ­a tÃ©cnica variada, donde un usuario puede buscar "smartphone resistente al agua" y encontrar productos descritos como "telÃ©fono mÃ³vil con certificaciÃ³n IP68". La **fusiÃ³n de rankings** mediante tÃ©cnicas como Reciprocal Rank Fusion (RRF) o aprendizaje automÃ¡tico permite combinar las fortalezas de ambos enfoques de manera Ã³ptima.

### Amazon S3: Escalabilidad y EconomÃ­a en Almacenamiento de Contenido Multimedia

La decisiÃ³n de utilizar **Amazon S3** para el almacenamiento de imÃ¡genes responde a consideraciones tanto tÃ©cnicas como econÃ³micas que son crÃ­ticas para la viabilidad comercial del sistema. S3 ofrece **durabilidad del 99.999999999% (11 9's)** y disponibilidad del 99.99%, garantizando que el contenido multimedia permanezca accesible incluso ante fallos de infraestructura.

La **arquitectura de almacenamiento por objetos** de S3 elimina las limitaciones de sistemas de archivos tradicionales, permitiendo escalabilidad prÃ¡cticamente ilimitada sin degradaciÃ³n del rendimiento. Esto es fundamental cuando se considera que las imÃ¡genes de productos de alta resoluciÃ³n pueden ocupar varios megabytes cada una, y un catÃ¡logo empresarial puede contener cientos de miles de productos.

El modelo de **precios por uso** de S3, combinado con opciones de almacenamiento inteligente (S3 Intelligent-Tiering) y clases de almacenamiento de acceso infrecuente, permite optimizar costos automÃ¡ticamente basÃ¡ndose en patrones de acceso reales. Para startups y PYMEs, esta elasticidad econÃ³mica es crucial para mantener mÃ¡rgenes sostenibles mientras se escala el negocio.

### IntegraciÃ³n ArquitectÃ³nica y Consideraciones de Rendimiento

La arquitectura propuesta aprovecha las **caracterÃ­sticas de localidad** inherentes tanto en PostgreSQL como en S3. Las consultas hÃ­bridas se ejecutan completamente en PostgreSQL, minimizando la latencia de red, mientras que las imÃ¡genes se sirven directamente desde S3 con **CloudFront CDN** para optimizar la entrega global.

Esta separaciÃ³n de responsabilidades permite **escalado independiente** de cada componente: la base de datos puede optimizarse para throughput de consultas mientras que el almacenamiento de imÃ¡genes se escala horizontalmente segÃºn demanda. La **consistencia eventual** entre metadatos en PostgreSQL e imÃ¡genes en S3 se gestiona mediante patrones de sincronizaciÃ³n asÃ­ncrona que mantienen la integridad del sistema sin bloqueos.

La implementaciÃ³n de **conexiones pooling** y **prepared statements** en PostgreSQL, combinada con **multipart uploads** y **transfer acceleration** en S3, garantiza que el sistema pueda manejar cargas de trabajo concurrentes tÃ­picas de aplicaciones de comercio electrÃ³nico en producciÃ³n.

---

## âš™ï¸ Inicio RÃ¡pido

### 1. Aplicar migraciones de base de datos
```powershell
python database\apply_migrations.py
````

### 2. Ingestar dataset desde S3 pÃºblico â†’ Parquet

```powershell
# Descarga y filtra (por defecto aplica paÃ­ses hispanohablantes y descripciÃ³n no nula)
python src\ingest\ingest_s3_csv.py --max-records 100000 --output-file "data/20250123_data.parquet"

# (Opcional) Filtrar ademÃ¡s por paÃ­ses especÃ­ficos (se intersecta con la lista hispanohablante)
python src\ingest\ingest_s3_csv.py --country-codes ES MX AR --output-file "data/latam_es.parquet"
```

### 3. Subir datos filtrados a Supabase/PostgreSQL

```powershell
python .\src\loader\upload_parquet_to_supabase.py
```

### 4. Rellenar embeddings (orden recomendado)

```powershell
# Texto â†’ Texto (principal: Jina JE-3)
python -m src.ingest.backfill_text_je3 --batch-size 128

# (Opcional) Texto â†’ Texto adicionales
python -m src.ingest.backfill_text_e5 --batch-size 512
python -m src.ingest.backfill_text_gte --batch-size 256

# Multimodal Jina CLIP v2 (texto e imagen 1024D)
python -m src.ingest.backfill_clip_v2 --mode text --batch-size 256
python -m src.ingest.backfill_clip_v2 --mode image --batch-size 128
```

> Nota: si prefieres la ruta CLIP 512D (texto multilingÃ¼e + ViT-B/32), usa `src/ingest/backfill_clip_512.py` con `--mode text_multi` e `--mode image`.

### 5. Ejecutar la API (uvicorn)

```powershell
uvicorn src.rag.chat_demo:app --reload --port 8000
```

### 6. Probar el chatbot y generar logs de trazabilidad

```powershell
pytest -q
```

Los resultados se guardan como JSON bajo `log/chat_run_<timestamp>/`:

- `00_meta.json`: contexto (envs, query, parÃ¡metros)
- `01_request.json`: peticiÃ³n enviada
- `02_response_status.json`: cÃ³digo HTTP y latencia
- `03_response_json.json`: respuesta completa (`answer` + `trace`)
- `04_sql.json`: SQL vectorial y lÃ©xico
- `05_candidates_vector_top.json`: top vectorial
- `06_candidates_lexical_top.json`: top lÃ©xico
- `07_final_fused.json`: ranking final fusionado (RRF)

---

## ğŸ“¦ Verificaciones opcionales de AWS CLI

Inspeccionar o descargar imÃ¡genes individuales del dataset pÃºblico:

```powershell
aws s3 ls s3://glovo-products-dataset-d1c9720d/dataset/YKKVTDF_0000672_1629430873.png --no-sign-request 

aws s3 cp s3://glovo-products-dataset-d1c9720d/dataset/YKKVTDF_0000672_1629430873.png . --no-sign-request
```

---

## ğŸ—‚ï¸ Estructura del Proyecto

```
lina/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ changelog/
â”‚   â””â”€â”€ CHANGELOG.md
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ data.parquet
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ apply_migrations.py
â”‚   â””â”€â”€ migrations/
â”‚       â”œâ”€â”€ 00_enable_extensions.sql
â”‚       â”œâ”€â”€ 01_create_schema.sql
â”‚       â”œâ”€â”€ 02_tables.sql
â”‚       â”œâ”€â”€ 03_indexes_hnsw.sql
â”‚       â””â”€â”€ [otros archivos SQL]
â”œâ”€â”€ models_cache/
â”‚   â”œâ”€â”€ models--jinaai--jina-embeddings-v3/
â”‚   â””â”€â”€ models--jinaai--xlm-roberta-flash-implementation/
â”œâ”€â”€ sandbox/
â”‚   â”œâ”€â”€ check_parquet.py
â”‚   â””â”€â”€ sample_foodi_dataset.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â”œâ”€â”€ text_je3.py
â”‚   â”‚   â”œâ”€â”€ clip_v2.py
â”‚   â”‚   â”œâ”€â”€ text_e5_small.py
â”‚   â”‚   â”œâ”€â”€ text_gte_base.py
â”‚   â”‚   â”œâ”€â”€ text_clip_multi.py
â”‚   â”‚   â””â”€â”€ image_clip_vitb32.py
â”‚   â”œâ”€â”€ ingest/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ backfill_text_je3.py
â”‚   â”‚   â”œâ”€â”€ backfill_clip_v2.py
â”‚   â”‚   â”œâ”€â”€ backfill_text_e5.py
â”‚   â”‚   â”œâ”€â”€ backfill_text_gte.py
â”‚   â”‚   â””â”€â”€ backfill_clip_512.py
â”‚   â””â”€â”€ loader/
â”‚       â””â”€â”€ upload_parquet_to_supabase.py
â”œâ”€â”€ .env.sample   # variables de entorno de ejemplo (aÃ±adir aquÃ­ los secretos necesarios)
â””â”€â”€ venv/         # entorno virtual (excluido en .gitignore)
```

---

## ğŸ”® PrÃ³ximos Pasos

* Implementar la interfaz de ejecuciÃ³n de consultas hÃ­bridas.
* Evaluar rendimiento con Precision@K, Recall@K, MAP, nDCG.
* Hacer benchmark de parÃ¡metros del Ã­ndice HNSW (`m`, `ef_search`, `ef_construction`).
* Preparar documentaciÃ³n y resultados de la tesis.

---

## ğŸ“– Referencias

* [pgvector](https://github.com/pgvector/pgvector)
* Radford et al. (2021) CLIP: Contrastive Language-Image Pretraining
* Manning et al. (2008) *Introduction to Information Retrieval*
* Jurafsky & Martin (2023) *Speech and Language Processing*

